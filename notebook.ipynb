{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira Semana de Estágio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementar o cutout, mixup, cutmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - mostrar imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(image_1, image_2,final_image,method):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image_1)\n",
    "    plt.title('Image 1')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(image_2)\n",
    "    plt.title('Image 2')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(final_image)\n",
    "    plt.title(method)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_1,final_image,method):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_1)\n",
    "    plt.title('Image 1')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(final_image)\n",
    "    plt.title(method)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Implementação do cutout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''CIFAR10/100 were normalized using per-channel mean\n",
    "and standard deviation. When required, we apply the standard data augmentation scheme for these datasets [5]. Images are first zero-padded with 4 pixels on each side to obtain a 40 × 40 pixel image, then a 32 × 32 crop is randomly\n",
    "extracted. Images are also randomly mirrored horizontally\n",
    "with 50% probability.\n",
    "Based on these validation results we select\n",
    "a cutout size of 16x16 pixels to use on CIFAR-10 and a cutout size of 8x8 pixels for CIFAR-100 when training on\n",
    "the full datasets.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(image, size):\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    y1 = np.random.randint(0, h-size)\n",
    "    y2 = y1 + size\n",
    "    x1 = np.random.randint(0, w-size)\n",
    "    x2 = x1 + size\n",
    "    position(y1,x1)\n",
    "    \n",
    "    image[y1:y2, x1:x2] = 0\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Implementação do mixup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivated by these issues, we introduce a simple and data-agnostic data augmentation routine, termed mixup (Section 2). In a nutshell, mixup constructs virtual training examples:\n",
    "- ``` X = λx1 + (1 − λ)xj , where xi, xj are raw input vectors ```\n",
    "- ```y˜ = λyi + (1 − λ)yj , where yi, yj are one-hot label encodings```\n",
    "\n",
    "(xi\n",
    ", yi) and (xj , yj ) are two examples drawn at random from our training data, and λ ∈ [0, 1].\n",
    "Therefore, mixup extends the training distribution by incorporating the prior knowledge that linear\n",
    "interpolations of feature vectors should lead to linear interpolations of the associated targets. mixup\n",
    "can be implemented in a few lines of code, and introduces minimal computation overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(image_1, image_2, label_1, label_2):\n",
    "    \n",
    "    lamba = np.random.uniform(0, 1)\n",
    "\n",
    "    mixed_image = lamba * image_1 + (1 - lamba) * image_2\n",
    "    \n",
    "    mixed_label = lamba * label_1 + (1 - lamba) * label_2\n",
    "    \n",
    "    return mixed_image.astype(np.uint8), mixed_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Implementação do cutmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hiperparametros do cutmix\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(y,x):\n",
    "    global coordenates\n",
    "    coordenates = (y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix(image_1, image_2, label_1, label_2,size):\n",
    "\n",
    "    lamba = np.random.beta(alpha, alpha)\n",
    "\n",
    "    cutout_image = cutout(image_1.copy(), size)\n",
    "    y,x = coordenates\n",
    "    \n",
    "    mixed_image = cutout_image\n",
    "    mixed_image[y:y+size, x:x+size] = image_2[y:y+size, x:x+size]\n",
    "    \n",
    "    mixed_label = lamba * label_1 + (1 - lamba) * label_2\n",
    "    \n",
    "    return mixed_image, mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix_(image_1, image_2, label_1, label_2):\n",
    "\n",
    "    lamba = np.random.beta(alpha, alpha)\n",
    "    \n",
    "    #mask\n",
    "    H,W = image_1.shape[0], image_1.shape[1]\n",
    "    \n",
    "    rw = int(W * np.sqrt(1 - lamba))\n",
    "    rh = int(H * np.sqrt(1- lamba))\n",
    "    rx = np.random.randint(0,W - rw)\n",
    "    ry = np.random.randint(0,H - rh)\n",
    "    '''\n",
    "    rx = np.random.randint(0,W)\n",
    "    ry = np.random.randint(0,H)\n",
    "    rw = int(W * np.sqrt(1 - lamba))\n",
    "    rh = int(H * np.sqrt(1- lamba))\n",
    "    '''\n",
    "    \n",
    "    mask = np.ones_like(image_1)\n",
    "    mask[ry:ry+rh, rx:rx+rw] = 0\n",
    "\n",
    "    mixed_image = mask * image_1 + (1 - mask) * image_2\n",
    "\n",
    "    mixed_label = lamba * label_1 + (1 - lamba) * label_2\n",
    "\n",
    "    return mixed_image, mixed_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a mascara tem que ser proporcional à imagem original ??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'c:\\Users\\Beatriz\\Desktop\\3 year (2023-2024)\\2ºsemestre\\estagio\\ordinal_augmentation\\exemplo.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image1 \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexemplo.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      2\u001b[0m image2 \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexemplo1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      4\u001b[0m label1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])  \n",
      "File \u001b[1;32mc:\\Users\\Beatriz\\.pyenv\\pyenv-win\\versions\\3.9.5\\lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m call_plugin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimread\u001b[39m\u001b[38;5;124m'\u001b[39m, fname, plugin\u001b[38;5;241m=\u001b[39mplugin, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplugin_args)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Beatriz\\.pyenv\\pyenv-win\\versions\\3.9.5\\lib\\site-packages\\skimage\\io\\manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Beatriz\\.pyenv\\pyenv-win\\versions\\3.9.5\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(imageio_imread(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\Beatriz\\.pyenv\\pyenv-win\\versions\\3.9.5\\lib\\site-packages\\imageio\\v3.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplugin_kwargs) \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n",
      "File \u001b[1;32mc:\\Users\\Beatriz\\.pyenv\\pyenv-win\\versions\\3.9.5\\lib\\site-packages\\imageio\\core\\imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Beatriz\\.pyenv\\pyenv-win\\versions\\3.9.5\\lib\\site-packages\\imageio\\core\\request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Beatriz\\.pyenv\\pyenv-win\\versions\\3.9.5\\lib\\site-packages\\imageio\\core\\request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_read_request:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fn):\n\u001b[1;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fn)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'c:\\Users\\Beatriz\\Desktop\\3 year (2023-2024)\\2ºsemestre\\estagio\\ordinal_augmentation\\exemplo.jpg'"
     ]
    }
   ],
   "source": [
    "image1 = io.imread('exemplo.jpg')  \n",
    "image2 = io.imread('exemplo1.jpg') \n",
    "\n",
    "label1 = np.array([0, 1])  \n",
    "label2 = np.array([1, 0])  \n",
    "\n",
    "image_cutout = cutout(image1.copy(), 40)\n",
    "image_mixup,_ = mixup(image1.copy(), image2.copy(), label1, label2)\n",
    "image_cutmix,_ = cutmix(image1.copy(), image2.copy(), label1, label2, 100)\n",
    "image_cutmix_,_ = cutmix_(image1.copy(), image2.copy(), label1, label2)\n",
    "\n",
    "display_image(image1, image_cutout, 'Cutout')\n",
    "display_images(image1, image2, image_mixup, 'Mixup')\n",
    "display_images(image1, image2, image_cutmix, 'Cutmix 1')\n",
    "display_images(image1, image2, image_cutmix_, 'Cutmix 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Semana de Estágio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reunião\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nadjacent ordinal mixup (https://arxiv.org/pdf/2007.06667.pdf)\\n\\ndef adjacent_ordinal_mixup(lista_imagens):\\n    k1 = ...  # [0,k-2]\\n    k2 = k1+1\\n    ....\\n\\n\\n\\nordinal mixup (airton tiago)\\n\\ndef ordinal_mixup(lista_imagens, tau):\\n    num_classes = len(lista_imagens)\\n    ...\\n\\ndef softmax(x):\\n    return x\\n\\ndef exp(center_class, num_classes, tau):\\n    kk = np.arange(0, num_classes)\\n    return softmax(np.exp(-np.abs(center_class-kk)/tau))\\n\\n# escolher aleatoriamente (de forma uniforme) uma classe [0, num_classes[\\n# probabilities = exp(...)\\n# x = sum(probabilities * x)\\n\\n\\n##################################################\\n\\n\\n\\ndef cutmix_ordinal(lista_imagens):\\n    probabilities = exp(...)\\n    (o que discutimos no papel)\\n'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "adjacent ordinal mixup (https://arxiv.org/pdf/2007.06667.pdf)\n",
    "\n",
    "def adjacent_ordinal_mixup(lista_imagens):\n",
    "    k1 = ...  # [0,k-2]\n",
    "    k2 = k1+1\n",
    "    ....\n",
    "\n",
    "\n",
    "\n",
    "ordinal mixup (airton tiago)\n",
    "\n",
    "def ordinal_mixup(lista_imagens, tau):\n",
    "    num_classes = len(lista_imagens)\n",
    "    ...\n",
    "\n",
    "def softmax(x):\n",
    "    return x\n",
    "\n",
    "def exp(center_class, num_classes, tau):\n",
    "    kk = np.arange(0, num_classes)\n",
    "    return softmax(np.exp(-np.abs(center_class-kk)/tau))\n",
    "\n",
    "# escolher aleatoriamente (de forma uniforme) uma classe [0, num_classes[\n",
    "# probabilities = exp(...)\n",
    "# x = sum(probabilities * x)\n",
    "\n",
    "\n",
    "##################################################\n",
    "\n",
    "\n",
    "\n",
    "def cutmix_ordinal(lista_imagens):\n",
    "    probabilities = exp(...)\n",
    "    (o que discutimos no papel)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_distance(H,W,area):\n",
    "    raiz_discriminante = math.sqrt((2*(H + W))**2 - 16* area)\n",
    "    distance = (-2*(H + W) + raiz_discriminante) / - 8\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_side(x,y,probabilities):\n",
    "    probability = 0\n",
    "    for k in range(x,y):\n",
    "        probability += probabilities[k]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagens_seguintes(num_inicial, num_final, valor, probabilities, H , W, list_images):\n",
    "    total_area = H*W\n",
    "    y = 0\n",
    "    x = 0\n",
    "    image_final = list_images[num_inicial+valor].copy()\n",
    "    image_final = image_final[y:H, x:W]\n",
    "    #plt.imshow(image_final)\n",
    "\n",
    "    print('num_final-num_inicial + 1:', num_final-num_inicial + 1)\n",
    "    for k in range(num_inicial+valor, num_final+valor, valor):\n",
    "        img_area = total_area*probabilities[k]\n",
    "        print('img_area:', img_area)\n",
    "        distance = int(calcular_distance(H,W,img_area))\n",
    "        print('distance:', distance)\n",
    "        num_inicial += valor\n",
    "        H -= 2*distance\n",
    "        W -= 2*distance\n",
    "        \n",
    "        x += distance\n",
    "        y += distance\n",
    "        \n",
    "        image_final[y:y+H, x:x+W] = list_images[k][y:y+H, x:x+W]\n",
    "        \n",
    "    return image_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def exp(num_classes, center_class, tau):\n",
    "#    return softmax(np.abs(center_class - num_classes) / tau)\n",
    "\n",
    "def exp(num_classes, center_class, tau):\n",
    "    # retorna um vector (com tamanho num_classes) com a distribuição def\n",
    "    # probabilidades para cada classe [0,num_classes[.\n",
    "    x = np.arange(num_classes)\n",
    "    return softmax(-np.abs(center_class - x) / tau)\n",
    "\n",
    "def mixup_images(list_images, lam):\n",
    "    mixup_image = np.sum(np.array(list_images) * lam[:, None, None, None], 0)\n",
    "    return mixup_image\n",
    "\n",
    "def create_lam(list_images):\n",
    "    size = len(list_images)\n",
    "    lam = np.zeros(size)\n",
    "    return size, lam\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def ordinal_mixup(list_images):\n",
    "    size, lam = create_lam(list_images)\n",
    "\n",
    "    class_1 = np.random.randint(0, size)\n",
    "    class_2 = np.random.randint(0, size)\n",
    "\n",
    "    beta = np.random.beta(alpha, alpha)\n",
    "\n",
    "    lam[class_1] = beta\n",
    "    lam[class_2] = 1 - beta\n",
    "\n",
    "    mixup_image = mixup_images(list_images, lam)\n",
    "    return mixup_image, lam\n",
    "\n",
    "def ordinal_adjacent_mixup(list_images):\n",
    "    size, lam = create_lam(list_images)\n",
    "\n",
    "    class_1 = np.random.randint(0, size - 2)\n",
    "    class_2 = class_1 + 1\n",
    "\n",
    "    beta = np.random.beta(alpha, alpha)\n",
    "\n",
    "    lam[class_1] = beta\n",
    "    lam[class_2] = 1 - beta\n",
    "\n",
    "    mixup_image = mixup_images(list_images, lam)\n",
    "    return mixup_image, lam\n",
    "\n",
    "def ordinal_exponencial_mixup(list_images, tau):\n",
    "    size, lam = create_lam(list_images)\n",
    "    l = np.random.randint(0, size) + 1\n",
    "    k = np.arange(1, size+1)\n",
    "    lam = exp(k,l, tau)\n",
    "\n",
    "    mixup_image = mixup_images(list_images, lam)\n",
    "    return mixup_image, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_cutmix(list_images,tau):\n",
    "    num_classes = len(list_images)\n",
    "    x = 0\n",
    "    y = 0\n",
    "    center_class = np.random.randint(0, num_classes)\n",
    "    probabilities = exp(num_classes,center_class, tau)\n",
    "    H, W = list_images[0].shape[0:2]\n",
    "    total_area = H*W\n",
    "    image_final = list_images[0].copy()\n",
    "\n",
    "    for i in range(0,num_classes-1):\n",
    "        img_area = total_area*probabilities[i]\n",
    "        distance = int(calcular_distance(H,W,img_area))\n",
    "        H -= 2*distance\n",
    "        W -= 2*distance\n",
    "        #mask = np.ones_like(list_images[i])\n",
    "        x += distance\n",
    "        y += distance\n",
    "        #mask[y:y+H, x:x+W] = 0\n",
    "        #image_final = mask * image_final + (1 - mask) * list_images[i+1]\n",
    "        image_final[y:y+H, x:x+W] = list_images[i+1][y:y+H, x:x+W]\n",
    "\n",
    "    return image_final\n",
    "\n",
    "def ordinal_cutmix_jaime(list_images, tau):\n",
    "    num_classes = len(list_images)\n",
    "    #center_class = np.random.randint(0, num_classes)\n",
    "    #probabilities = exp(num_classes,center_class, tau)\n",
    "    center_class = 3\n",
    "    probabilities = [0.15, 0.15, 0.3, 0.4, 0, 0, 0]\n",
    "\n",
    "    H, W = list_images[0].shape[0:2]\n",
    "    total_area = H*W\n",
    "    image_final = list_images[center_class].copy()\n",
    "\n",
    "    probability_left = np.sum(probabilities[0:center_class]) #probability_side(0,center_class,probabilities)\n",
    "    probability_rigth = np.sum(probabilities[center_class+1:])\n",
    "\n",
    "    area_left = total_area * probability_left\n",
    "    area_rigth = total_area * probability_rigth\n",
    "\n",
    "    #supondo que o imagem vai ser um quadrado\n",
    "    H_left = int(np.sqrt(area_left))\n",
    "    H_rigth = int(np.sqrt(area_rigth))\n",
    "\n",
    "    print(\"central :\",center_class)\n",
    "    print(\"probabilities:\", probabilities)\n",
    "    print(\"H_left:\", H_left)\n",
    "\n",
    "    image_left = imagens_seguintes(center_class, 0, -1, probabilities, H_left , H_left, list_images)\n",
    "    image_rigth = imagens_seguintes(center_class, num_classes, +1, probabilities, H_rigth , H_rigth, list_images)\n",
    "\n",
    "    #def imagens_seguintes(num_inicial, num_final, valor, probabilities, H , W, list_images):\n",
    "\n",
    "    image_final[0:H_left,0:H_left] = image_left\n",
    "    #image_final[256-H_rigth:256,256-H_rigth:256] = image_rigth\n",
    "    return image_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    images = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".BMP\"):\n",
    "                img = io.imread(os.path.join(root, filename))\n",
    "                img = resize(img,(256, 256))\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "list_images = load_images('smear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ordinal_cutmix_jaime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images_final \u001b[38;5;241m=\u001b[39m \u001b[43mordinal_cutmix_jaime\u001b[49m(list_images,\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(images_final)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ordinal_cutmix_jaime' is not defined"
     ]
    }
   ],
   "source": [
    "images_final = ordinal_cutmix_jaime(list_images,0.5)\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.imshow(images_final)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beatriz\\AppData\\Local\\Temp\\ipykernel_16584\\3455310050.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return j * torch.log(f_x) - f_x - torch.lgamma(torch.tensor(j))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3973])\n",
      "tensor([   -inf, -1.9014, -0.8028, -0.3973, -0.3973, -0.6850, -1.1958, -1.8890,\n",
      "        -2.7363, -3.7171])\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def poisson_pmf_log(f_x, j):\n",
    "    return j * torch.log(f_x) - f_x - torch.lgamma(torch.tensor(j))\n",
    "\n",
    "def ordinal_probabilities(k, K, tau=1.0):\n",
    "\n",
    "    # Calcular h(x)_j para cada categoria j\n",
    "    h_x_j = torch.tensor([poisson_pmf_log(k, k)])\n",
    "    h_x = poisson_pmf_log(k, j) for j in range(0,K)])\n",
    "    print(h_x_j)\n",
    "    print(h_x)\n",
    "    \n",
    "    # Calcular as probabilidades usando softmax com o parâmetro tau\n",
    "    probabilities_a = F.softmax((-h_x_j / tau), dim=0)\n",
    "    probabilities_d =  F.softmax((-h_x / tau),dim=0)\n",
    "    probabilities = probabilities_a/probabilities_d\n",
    "    print(probabilities_)\n",
    "    return probabilities\n",
    "\n",
    "# Parâmetros\n",
    "k = torch.tensor(3.0)\n",
    "K = 10  # número de categorias ordinais\n",
    "tau = 1.0  # valor de tau (pode ser ajustado conforme necessário)\n",
    "\n",
    "# Gerar probabilidades ordinais\n",
    "ordinal_probs = ordinal_probabilities(k, K, tau)\n",
    "\n",
    "# Plotar as probabilidades ordinais\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, K + 1), ordinal_probs.numpy())\n",
    "plt.xlabel('Ordinal Category')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Ordinal Probabilities p(y=j|x) (f(x)={k.item()}, τ={tau})')\n",
    "plt.xticks(range(1, K + 1))  # Ajustar os ticks do eixo x para representar categorias ordinais\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6403, 0.9308, 0.4505, 0.3241, 0.0800, 0.4985, 0.9775])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"poisson_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[208], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m rates \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(num_class)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(rates)\n\u001b[1;32m----> 7\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoisson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(p)\n\u001b[0;32m     10\u001b[0m probabilities_a \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(p)\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1.0\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"poisson_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_class = 7\n",
    "rates = torch.rand(num_class)\n",
    "p = torch.poisson(rates)\n",
    "\n",
    "\n",
    "probabilities_a = F.softmax(-torch.log(p)/ 1.0, dim=0)\n",
    "\n",
    "probabilities_b = torch.zeros(num_class)\n",
    "\n",
    "for K in range(1,num_class):\n",
    "    t = rates*K\n",
    "    probabilities_b += torch.poisson(t)\n",
    "\n",
    "probabilities_b = torch.tensor(probabilities_b)\n",
    "\n",
    "print(probabilities_b)\n",
    "\n",
    "probabilities = probabilities_a / probabilities_b\n",
    "print(probabilities)\n",
    "print(sum(probabilities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(num_classes, center_class, tau, device):\n",
    "    x = torch.arange(num_classes, dtype=torch.float, device= device)\n",
    "    return torch.nn.functional.softmax(-torch.abs(center_class[:, None] - x[None, :]) / tau, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0209, 0.0939, 0.2114, 0.3171, 0.3567]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def unimodal_poisson_probabilities(num_classes, target_class, tau, device):\n",
    "    # https://proceedings.mlr.press/v70/beckham17a/beckham17a.pdf\n",
    "    _lambda = target_class[:, None]+0.5  # to ensure mode falls only on this class\n",
    "    j = torch.arange(num_classes, dtype=torch.float, device=device)[None]\n",
    "    log_pmf = j*torch.log(_lambda) - _lambda - torch.lgamma(j+1)\n",
    "    return torch.softmax(log_pmf/tau, 1)\n",
    "\n",
    "def poisson(num_classes, target_class):\n",
    "    _lambda = target_class[:, None]+0.5  # to ensure mode falls only on this class\n",
    "    j = torch.arange(num_classes, dtype=torch.float)[None]\n",
    "    return ((_lambda**j) * torch.exp(-_lambda)) / torch.exp(torch.lgamma(j+1))\n",
    "\n",
    "# durante o treino: tau = tau_max * (1-epoch/epochs)\n",
    "\n",
    "num_classes = torch.tensor(5)\n",
    "target_class = torch.tensor([4])\n",
    "\n",
    "# Gera as probabilidades\n",
    "probabilities = unimodal_poisson_probabilities(num_classes, target_class, 1, 'cpu')\n",
    "print(probabilities)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(0, num_classes), probabilities.numpy().flatten())\n",
    "plt.xlabel('Ordinal Category')\n",
    "plt.ylabel('Probability')\n",
    "plt.xticks(range(0, num_classes ))  # Ajustar os ticks do eixo x para representar categorias ordinais\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anterior: None\n",
      "atual tensor([[1.9392e-09, 5.3495e-04, 1.4411e-01, 6.7322e-01, 1.7711e-01, 5.0029e-03,\n",
      "         2.2824e-05]])\n",
      "anterior: tensor([[1.9392e-09, 5.3495e-04, 1.4411e-01, 6.7322e-01, 1.7711e-01, 5.0029e-03,\n",
      "         2.2824e-05]])\n",
      "atual tensor([[2.5608e-05, 1.3450e-02, 2.2075e-01, 4.7714e-01, 2.4473e-01, 4.1131e-02,\n",
      "         2.7782e-03]])\n",
      "tensor(0.1961)\n",
      "anterior: tensor([[2.5608e-05, 1.3450e-02, 2.2075e-01, 4.7714e-01, 2.4473e-01, 4.1131e-02,\n",
      "         2.7782e-03]])\n",
      "atual tensor([[0.0006, 0.0362, 0.2336, 0.3905, 0.2502, 0.0762, 0.0126]])\n",
      "tensor(0.0866)\n",
      "anterior: tensor([[0.0006, 0.0362, 0.2336, 0.3905, 0.2502, 0.0762, 0.0126]])\n",
      "atual tensor([[0.0025, 0.0571, 0.2312, 0.3400, 0.2435, 0.0998, 0.0259]])\n",
      "tensor(0.0506)\n",
      "anterior: tensor([[0.0025, 0.0571, 0.2312, 0.3400, 0.2435, 0.0998, 0.0259]])\n",
      "atual tensor([[0.0060, 0.0735, 0.2252, 0.3065, 0.2347, 0.1150, 0.0391]])\n",
      "tensor(0.0335)\n",
      "anterior: tensor([[0.0060, 0.0735, 0.2252, 0.3065, 0.2347, 0.1150, 0.0391]])\n",
      "atual tensor([[0.0107, 0.0860, 0.2186, 0.2827, 0.2263, 0.1249, 0.0509]])\n",
      "tensor(0.0238)\n",
      "anterior: tensor([[0.0107, 0.0860, 0.2186, 0.2827, 0.2263, 0.1249, 0.0509]])\n",
      "atual tensor([[0.0160, 0.0955, 0.2125, 0.2648, 0.2188, 0.1315, 0.0609]])\n",
      "tensor(0.0178)\n",
      "anterior: tensor([[0.0160, 0.0955, 0.2125, 0.2648, 0.2188, 0.1315, 0.0609]])\n",
      "atual tensor([[0.0215, 0.1028, 0.2070, 0.2510, 0.2124, 0.1360, 0.0693]])\n",
      "tensor(0.0139)\n",
      "anterior: tensor([[0.0215, 0.1028, 0.2070, 0.2510, 0.2124, 0.1360, 0.0693]])\n",
      "atual tensor([[0.0270, 0.1085, 0.2021, 0.2399, 0.2068, 0.1392, 0.0765]])\n",
      "tensor(0.0111)\n",
      "anterior: tensor([[0.0270, 0.1085, 0.2021, 0.2399, 0.2068, 0.1392, 0.0765]])\n",
      "atual tensor([[0.0323, 0.1131, 0.1979, 0.2309, 0.2020, 0.1414, 0.0825]])\n",
      "tensor(0.0090)\n",
      "anterior: tensor([[0.0323, 0.1131, 0.1979, 0.2309, 0.2020, 0.1414, 0.0825]])\n",
      "atual tensor([[0.0374, 0.1167, 0.1941, 0.2233, 0.1978, 0.1430, 0.0876]])\n",
      "tensor(0.0075)\n",
      "anterior: tensor([[0.0374, 0.1167, 0.1941, 0.2233, 0.1978, 0.1430, 0.0876]])\n",
      "atual tensor([[0.0421, 0.1197, 0.1908, 0.2170, 0.1941, 0.1442, 0.0920]])\n",
      "tensor(0.0064)\n",
      "anterior: tensor([[0.0421, 0.1197, 0.1908, 0.2170, 0.1941, 0.1442, 0.0920]])\n",
      "atual tensor([[0.0466, 0.1222, 0.1879, 0.2115, 0.1909, 0.1451, 0.0958]])\n",
      "tensor(0.0054)\n",
      "anterior: tensor([[0.0466, 0.1222, 0.1879, 0.2115, 0.1909, 0.1451, 0.0958]])\n",
      "atual tensor([[0.0508, 0.1242, 0.1853, 0.2068, 0.1880, 0.1457, 0.0992]])\n",
      "tensor(0.0047)\n",
      "anterior: tensor([[0.0508, 0.1242, 0.1853, 0.2068, 0.1880, 0.1457, 0.0992]])\n",
      "atual tensor([[0.0546, 0.1260, 0.1829, 0.2027, 0.1855, 0.1462, 0.1021]])\n",
      "tensor(0.0041)\n",
      "anterior: tensor([[0.0546, 0.1260, 0.1829, 0.2027, 0.1855, 0.1462, 0.1021]])\n",
      "atual tensor([[0.0583, 0.1275, 0.1808, 0.1991, 0.1832, 0.1466, 0.1046]])\n",
      "tensor(0.0036)\n",
      "anterior: tensor([[0.0583, 0.1275, 0.1808, 0.1991, 0.1832, 0.1466, 0.1046]])\n",
      "atual tensor([[0.0616, 0.1287, 0.1789, 0.1959, 0.1811, 0.1468, 0.1069]])\n",
      "tensor(0.0034)\n",
      "anterior: tensor([[0.0616, 0.1287, 0.1789, 0.1959, 0.1811, 0.1468, 0.1069]])\n",
      "atual tensor([[0.0647, 0.1298, 0.1772, 0.1930, 0.1792, 0.1470, 0.1090]])\n",
      "tensor(0.0031)\n",
      "anterior: tensor([[0.0647, 0.1298, 0.1772, 0.1930, 0.1792, 0.1470, 0.1090]])\n",
      "atual tensor([[0.0677, 0.1308, 0.1756, 0.1905, 0.1775, 0.1471, 0.1108]])\n",
      "tensor(0.0029)\n",
      "anterior: tensor([[0.0677, 0.1308, 0.1756, 0.1905, 0.1775, 0.1471, 0.1108]])\n",
      "atual tensor([[0.0704, 0.1317, 0.1742, 0.1881, 0.1760, 0.1472, 0.1125]])\n",
      "tensor(0.0027)\n",
      "anterior: tensor([[0.0704, 0.1317, 0.1742, 0.1881, 0.1760, 0.1472, 0.1125]])\n",
      "atual tensor([[0.0729, 0.1324, 0.1729, 0.1860, 0.1746, 0.1473, 0.1139]])\n",
      "tensor(0.0025)\n",
      "anterior: tensor([[0.0729, 0.1324, 0.1729, 0.1860, 0.1746, 0.1473, 0.1139]])\n",
      "atual tensor([[0.0753, 0.1331, 0.1716, 0.1841, 0.1733, 0.1473, 0.1153]])\n",
      "tensor(0.0024)\n",
      "anterior: tensor([[0.0753, 0.1331, 0.1716, 0.1841, 0.1733, 0.1473, 0.1153]])\n",
      "atual tensor([[0.0775, 0.1337, 0.1705, 0.1823, 0.1720, 0.1473, 0.1166]])\n",
      "tensor(0.0022)\n",
      "anterior: tensor([[0.0775, 0.1337, 0.1705, 0.1823, 0.1720, 0.1473, 0.1166]])\n",
      "atual tensor([[0.0796, 0.1342, 0.1695, 0.1807, 0.1709, 0.1473, 0.1177]])\n",
      "tensor(0.0021)\n",
      "anterior: tensor([[0.0796, 0.1342, 0.1695, 0.1807, 0.1709, 0.1473, 0.1177]])\n",
      "atual tensor([[0.0816, 0.1347, 0.1685, 0.1792, 0.1699, 0.1473, 0.1187]])\n",
      "tensor(0.0020)\n",
      "anterior: tensor([[0.0816, 0.1347, 0.1685, 0.1792, 0.1699, 0.1473, 0.1187]])\n",
      "atual tensor([[0.0835, 0.1351, 0.1676, 0.1778, 0.1689, 0.1473, 0.1197]])\n",
      "tensor(0.0019)\n",
      "anterior: tensor([[0.0835, 0.1351, 0.1676, 0.1778, 0.1689, 0.1473, 0.1197]])\n",
      "atual tensor([[0.0852, 0.1355, 0.1668, 0.1766, 0.1680, 0.1472, 0.1206]])\n",
      "tensor(0.0018)\n",
      "anterior: tensor([[0.0852, 0.1355, 0.1668, 0.1766, 0.1680, 0.1472, 0.1206]])\n",
      "atual tensor([[0.0869, 0.1359, 0.1660, 0.1754, 0.1672, 0.1472, 0.1214]])\n",
      "tensor(0.0017)\n",
      "anterior: tensor([[0.0869, 0.1359, 0.1660, 0.1754, 0.1672, 0.1472, 0.1214]])\n",
      "atual tensor([[0.0885, 0.1362, 0.1652, 0.1743, 0.1664, 0.1472, 0.1222]])\n",
      "tensor(0.0016)\n",
      "anterior: tensor([[0.0885, 0.1362, 0.1652, 0.1743, 0.1664, 0.1472, 0.1222]])\n",
      "atual tensor([[0.0899, 0.1366, 0.1646, 0.1732, 0.1657, 0.1471, 0.1229]])\n",
      "tensor(0.0015)\n",
      "anterior: tensor([[0.0899, 0.1366, 0.1646, 0.1732, 0.1657, 0.1471, 0.1229]])\n",
      "atual tensor([[0.0913, 0.1368, 0.1639, 0.1723, 0.1650, 0.1471, 0.1236]])\n",
      "tensor(0.0014)\n",
      "anterior: tensor([[0.0913, 0.1368, 0.1639, 0.1723, 0.1650, 0.1471, 0.1236]])\n",
      "atual tensor([[0.0927, 0.1371, 0.1633, 0.1714, 0.1643, 0.1470, 0.1242]])\n",
      "tensor(0.0013)\n",
      "anterior: tensor([[0.0927, 0.1371, 0.1633, 0.1714, 0.1643, 0.1470, 0.1242]])\n",
      "atual tensor([[0.0940, 0.1373, 0.1627, 0.1705, 0.1637, 0.1470, 0.1248]])\n",
      "tensor(0.0013)\n",
      "anterior: tensor([[0.0940, 0.1373, 0.1627, 0.1705, 0.1637, 0.1470, 0.1248]])\n",
      "atual tensor([[0.0952, 0.1376, 0.1622, 0.1697, 0.1632, 0.1469, 0.1254]])\n",
      "tensor(0.0012)\n",
      "anterior: tensor([[0.0952, 0.1376, 0.1622, 0.1697, 0.1632, 0.1469, 0.1254]])\n",
      "atual tensor([[0.0963, 0.1378, 0.1616, 0.1689, 0.1626, 0.1469, 0.1259]])\n",
      "tensor(0.0012)\n",
      "anterior: tensor([[0.0963, 0.1378, 0.1616, 0.1689, 0.1626, 0.1469, 0.1259]])\n",
      "atual tensor([[0.0974, 0.1380, 0.1612, 0.1682, 0.1621, 0.1468, 0.1264]])\n",
      "tensor(0.0011)\n",
      "anterior: tensor([[0.0974, 0.1380, 0.1612, 0.1682, 0.1621, 0.1468, 0.1264]])\n",
      "atual tensor([[0.0985, 0.1381, 0.1607, 0.1675, 0.1616, 0.1467, 0.1268]])\n",
      "tensor(0.0010)\n",
      "anterior: tensor([[0.0985, 0.1381, 0.1607, 0.1675, 0.1616, 0.1467, 0.1268]])\n",
      "atual tensor([[0.0995, 0.1383, 0.1602, 0.1669, 0.1611, 0.1467, 0.1273]])\n",
      "tensor(0.0010)\n",
      "anterior: tensor([[0.0995, 0.1383, 0.1602, 0.1669, 0.1611, 0.1467, 0.1273]])\n",
      "atual tensor([[0.1004, 0.1385, 0.1598, 0.1663, 0.1607, 0.1466, 0.1277]])\n",
      "tensor(0.0010)\n",
      "anterior: tensor([[0.1004, 0.1385, 0.1598, 0.1663, 0.1607, 0.1466, 0.1277]])\n",
      "atual tensor([[0.1013, 0.1386, 0.1594, 0.1657, 0.1603, 0.1466, 0.1281]])\n",
      "tensor(0.0009)\n",
      "anterior: tensor([[0.1013, 0.1386, 0.1594, 0.1657, 0.1603, 0.1466, 0.1281]])\n",
      "atual tensor([[0.1022, 0.1388, 0.1590, 0.1651, 0.1598, 0.1465, 0.1285]])\n",
      "tensor(0.0009)\n",
      "anterior: tensor([[0.1022, 0.1388, 0.1590, 0.1651, 0.1598, 0.1465, 0.1285]])\n",
      "atual tensor([[0.1031, 0.1389, 0.1587, 0.1646, 0.1595, 0.1465, 0.1288]])\n",
      "tensor(0.0008)\n",
      "anterior: tensor([[0.1031, 0.1389, 0.1587, 0.1646, 0.1595, 0.1465, 0.1288]])\n",
      "atual tensor([[0.1039, 0.1390, 0.1583, 0.1641, 0.1591, 0.1464, 0.1292]])\n",
      "tensor(0.0008)\n",
      "anterior: tensor([[0.1039, 0.1390, 0.1583, 0.1641, 0.1591, 0.1464, 0.1292]])\n",
      "atual tensor([[0.1047, 0.1391, 0.1580, 0.1636, 0.1587, 0.1464, 0.1295]])\n",
      "tensor(0.0008)\n",
      "anterior: tensor([[0.1047, 0.1391, 0.1580, 0.1636, 0.1587, 0.1464, 0.1295]])\n",
      "atual tensor([[0.1054, 0.1392, 0.1577, 0.1632, 0.1584, 0.1463, 0.1298]])\n",
      "tensor(0.0007)\n",
      "anterior: tensor([[0.1054, 0.1392, 0.1577, 0.1632, 0.1584, 0.1463, 0.1298]])\n",
      "atual tensor([[0.1061, 0.1393, 0.1574, 0.1627, 0.1581, 0.1463, 0.1301]])\n",
      "tensor(0.0007)\n",
      "anterior: tensor([[0.1061, 0.1393, 0.1574, 0.1627, 0.1581, 0.1463, 0.1301]])\n",
      "atual tensor([[0.1068, 0.1394, 0.1571, 0.1623, 0.1578, 0.1462, 0.1304]])\n",
      "tensor(0.0007)\n",
      "anterior: tensor([[0.1068, 0.1394, 0.1571, 0.1623, 0.1578, 0.1462, 0.1304]])\n",
      "atual tensor([[0.1075, 0.1395, 0.1568, 0.1619, 0.1575, 0.1462, 0.1307]])\n",
      "tensor(0.0007)\n",
      "anterior: tensor([[0.1075, 0.1395, 0.1568, 0.1619, 0.1575, 0.1462, 0.1307]])\n",
      "atual tensor([[0.1081, 0.1396, 0.1565, 0.1615, 0.1572, 0.1461, 0.1309]])\n",
      "tensor(0.0006)\n",
      "anterior: tensor([[0.1081, 0.1396, 0.1565, 0.1615, 0.1572, 0.1461, 0.1309]])\n",
      "atual tensor([[0.1087, 0.1397, 0.1563, 0.1611, 0.1569, 0.1461, 0.1312]])\n",
      "tensor(0.0006)\n",
      "anterior: tensor([[0.1087, 0.1397, 0.1563, 0.1611, 0.1569, 0.1461, 0.1312]])\n",
      "atual tensor([[0.1093, 0.1398, 0.1560, 0.1608, 0.1566, 0.1461, 0.1314]])\n",
      "tensor(0.0006)\n",
      "anterior: tensor([[0.1093, 0.1398, 0.1560, 0.1608, 0.1566, 0.1461, 0.1314]])\n",
      "atual tensor([[0.1099, 0.1399, 0.1558, 0.1604, 0.1564, 0.1460, 0.1316]])\n",
      "tensor(0.0006)\n",
      "anterior: tensor([[0.1099, 0.1399, 0.1558, 0.1604, 0.1564, 0.1460, 0.1316]])\n",
      "atual tensor([[0.1105, 0.1399, 0.1555, 0.1601, 0.1561, 0.1460, 0.1319]])\n",
      "tensor(0.0006)\n",
      "anterior: tensor([[0.1105, 0.1399, 0.1555, 0.1601, 0.1561, 0.1460, 0.1319]])\n",
      "atual tensor([[0.1110, 0.1400, 0.1553, 0.1598, 0.1559, 0.1459, 0.1321]])\n",
      "tensor(0.0005)\n",
      "anterior: tensor([[0.1110, 0.1400, 0.1553, 0.1598, 0.1559, 0.1459, 0.1321]])\n",
      "atual tensor([[0.1115, 0.1401, 0.1551, 0.1595, 0.1557, 0.1459, 0.1323]])\n",
      "tensor(0.0005)\n",
      "anterior: tensor([[0.1115, 0.1401, 0.1551, 0.1595, 0.1557, 0.1459, 0.1323]])\n",
      "atual tensor([[0.1120, 0.1401, 0.1549, 0.1592, 0.1554, 0.1458, 0.1325]])\n",
      "tensor(0.0005)\n",
      "anterior: tensor([[0.1120, 0.1401, 0.1549, 0.1592, 0.1554, 0.1458, 0.1325]])\n",
      "atual tensor([[0.1125, 0.1402, 0.1547, 0.1589, 0.1552, 0.1458, 0.1327]])\n",
      "tensor(0.0005)\n",
      "anterior: tensor([[0.1125, 0.1402, 0.1547, 0.1589, 0.1552, 0.1458, 0.1327]])\n",
      "atual tensor([[0.1130, 0.1403, 0.1545, 0.1586, 0.1550, 0.1458, 0.1328]])\n",
      "tensor(0.0005)\n",
      "anterior: tensor([[0.1130, 0.1403, 0.1545, 0.1586, 0.1550, 0.1458, 0.1328]])\n",
      "atual tensor([[0.1135, 0.1403, 0.1543, 0.1584, 0.1548, 0.1457, 0.1330]])\n",
      "tensor(0.0005)\n",
      "anterior: tensor([[0.1135, 0.1403, 0.1543, 0.1584, 0.1548, 0.1457, 0.1330]])\n",
      "atual tensor([[0.1139, 0.1404, 0.1541, 0.1581, 0.1546, 0.1457, 0.1332]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1139, 0.1404, 0.1541, 0.1581, 0.1546, 0.1457, 0.1332]])\n",
      "atual tensor([[0.1144, 0.1404, 0.1539, 0.1579, 0.1544, 0.1457, 0.1333]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1144, 0.1404, 0.1539, 0.1579, 0.1544, 0.1457, 0.1333]])\n",
      "atual tensor([[0.1148, 0.1405, 0.1537, 0.1576, 0.1543, 0.1456, 0.1335]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1148, 0.1405, 0.1537, 0.1576, 0.1543, 0.1456, 0.1335]])\n",
      "atual tensor([[0.1152, 0.1405, 0.1536, 0.1574, 0.1541, 0.1456, 0.1337]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1152, 0.1405, 0.1536, 0.1574, 0.1541, 0.1456, 0.1337]])\n",
      "atual tensor([[0.1156, 0.1406, 0.1534, 0.1572, 0.1539, 0.1456, 0.1338]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1156, 0.1406, 0.1534, 0.1572, 0.1539, 0.1456, 0.1338]])\n",
      "atual tensor([[0.1160, 0.1406, 0.1533, 0.1569, 0.1537, 0.1455, 0.1340]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1160, 0.1406, 0.1533, 0.1569, 0.1537, 0.1455, 0.1340]])\n",
      "atual tensor([[0.1163, 0.1407, 0.1531, 0.1567, 0.1536, 0.1455, 0.1341]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1163, 0.1407, 0.1531, 0.1567, 0.1536, 0.1455, 0.1341]])\n",
      "atual tensor([[0.1167, 0.1407, 0.1530, 0.1565, 0.1534, 0.1455, 0.1342]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1167, 0.1407, 0.1530, 0.1565, 0.1534, 0.1455, 0.1342]])\n",
      "atual tensor([[0.1171, 0.1407, 0.1528, 0.1563, 0.1533, 0.1454, 0.1344]])\n",
      "tensor(0.0004)\n",
      "anterior: tensor([[0.1171, 0.1407, 0.1528, 0.1563, 0.1533, 0.1454, 0.1344]])\n",
      "atual tensor([[0.1174, 0.1408, 0.1527, 0.1561, 0.1531, 0.1454, 0.1345]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1174, 0.1408, 0.1527, 0.1561, 0.1531, 0.1454, 0.1345]])\n",
      "atual tensor([[0.1177, 0.1408, 0.1525, 0.1559, 0.1530, 0.1454, 0.1346]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1177, 0.1408, 0.1525, 0.1559, 0.1530, 0.1454, 0.1346]])\n",
      "atual tensor([[0.1181, 0.1409, 0.1524, 0.1557, 0.1528, 0.1454, 0.1347]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1181, 0.1409, 0.1524, 0.1557, 0.1528, 0.1454, 0.1347]])\n",
      "atual tensor([[0.1184, 0.1409, 0.1523, 0.1556, 0.1527, 0.1453, 0.1348]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1184, 0.1409, 0.1523, 0.1556, 0.1527, 0.1453, 0.1348]])\n",
      "atual tensor([[0.1187, 0.1409, 0.1521, 0.1554, 0.1526, 0.1453, 0.1350]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1187, 0.1409, 0.1521, 0.1554, 0.1526, 0.1453, 0.1350]])\n",
      "atual tensor([[0.1190, 0.1410, 0.1520, 0.1552, 0.1524, 0.1453, 0.1351]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1190, 0.1410, 0.1520, 0.1552, 0.1524, 0.1453, 0.1351]])\n",
      "atual tensor([[0.1193, 0.1410, 0.1519, 0.1551, 0.1523, 0.1452, 0.1352]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1193, 0.1410, 0.1519, 0.1551, 0.1523, 0.1452, 0.1352]])\n",
      "atual tensor([[0.1196, 0.1410, 0.1518, 0.1549, 0.1522, 0.1452, 0.1353]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1196, 0.1410, 0.1518, 0.1549, 0.1522, 0.1452, 0.1353]])\n",
      "atual tensor([[0.1199, 0.1410, 0.1517, 0.1547, 0.1521, 0.1452, 0.1354]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1199, 0.1410, 0.1517, 0.1547, 0.1521, 0.1452, 0.1354]])\n",
      "atual tensor([[0.1201, 0.1411, 0.1516, 0.1546, 0.1520, 0.1452, 0.1355]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1201, 0.1411, 0.1516, 0.1546, 0.1520, 0.1452, 0.1355]])\n",
      "atual tensor([[0.1204, 0.1411, 0.1515, 0.1544, 0.1519, 0.1452, 0.1356]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1204, 0.1411, 0.1515, 0.1544, 0.1519, 0.1452, 0.1356]])\n",
      "atual tensor([[0.1207, 0.1411, 0.1514, 0.1543, 0.1517, 0.1451, 0.1357]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1207, 0.1411, 0.1514, 0.1543, 0.1517, 0.1451, 0.1357]])\n",
      "atual tensor([[0.1209, 0.1412, 0.1513, 0.1542, 0.1516, 0.1451, 0.1358]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1209, 0.1412, 0.1513, 0.1542, 0.1516, 0.1451, 0.1358]])\n",
      "atual tensor([[0.1212, 0.1412, 0.1512, 0.1540, 0.1515, 0.1451, 0.1359]])\n",
      "tensor(0.0003)\n",
      "anterior: tensor([[0.1212, 0.1412, 0.1512, 0.1540, 0.1515, 0.1451, 0.1359]])\n",
      "atual tensor([[0.1214, 0.1412, 0.1511, 0.1539, 0.1514, 0.1451, 0.1359]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1214, 0.1412, 0.1511, 0.1539, 0.1514, 0.1451, 0.1359]])\n",
      "atual tensor([[0.1217, 0.1412, 0.1510, 0.1538, 0.1513, 0.1450, 0.1360]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1217, 0.1412, 0.1510, 0.1538, 0.1513, 0.1450, 0.1360]])\n",
      "atual tensor([[0.1219, 0.1413, 0.1509, 0.1536, 0.1512, 0.1450, 0.1361]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1219, 0.1413, 0.1509, 0.1536, 0.1512, 0.1450, 0.1361]])\n",
      "atual tensor([[0.1221, 0.1413, 0.1508, 0.1535, 0.1511, 0.1450, 0.1362]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1221, 0.1413, 0.1508, 0.1535, 0.1511, 0.1450, 0.1362]])\n",
      "atual tensor([[0.1223, 0.1413, 0.1507, 0.1534, 0.1510, 0.1450, 0.1363]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1223, 0.1413, 0.1507, 0.1534, 0.1510, 0.1450, 0.1363]])\n",
      "atual tensor([[0.1226, 0.1413, 0.1506, 0.1533, 0.1510, 0.1450, 0.1363]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1226, 0.1413, 0.1506, 0.1533, 0.1510, 0.1450, 0.1363]])\n",
      "atual tensor([[0.1228, 0.1413, 0.1505, 0.1531, 0.1509, 0.1449, 0.1364]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1228, 0.1413, 0.1505, 0.1531, 0.1509, 0.1449, 0.1364]])\n",
      "atual tensor([[0.1230, 0.1414, 0.1504, 0.1530, 0.1508, 0.1449, 0.1365]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1230, 0.1414, 0.1504, 0.1530, 0.1508, 0.1449, 0.1365]])\n",
      "atual tensor([[0.1232, 0.1414, 0.1503, 0.1529, 0.1507, 0.1449, 0.1366]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1232, 0.1414, 0.1503, 0.1529, 0.1507, 0.1449, 0.1366]])\n",
      "atual tensor([[0.1234, 0.1414, 0.1503, 0.1528, 0.1506, 0.1449, 0.1366]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1234, 0.1414, 0.1503, 0.1528, 0.1506, 0.1449, 0.1366]])\n",
      "atual tensor([[0.1236, 0.1414, 0.1502, 0.1527, 0.1505, 0.1449, 0.1367]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1236, 0.1414, 0.1502, 0.1527, 0.1505, 0.1449, 0.1367]])\n",
      "atual tensor([[0.1238, 0.1414, 0.1501, 0.1526, 0.1504, 0.1448, 0.1368]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1238, 0.1414, 0.1501, 0.1526, 0.1504, 0.1448, 0.1368]])\n",
      "atual tensor([[0.1240, 0.1415, 0.1500, 0.1525, 0.1504, 0.1448, 0.1368]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1240, 0.1415, 0.1500, 0.1525, 0.1504, 0.1448, 0.1368]])\n",
      "atual tensor([[0.1242, 0.1415, 0.1500, 0.1524, 0.1503, 0.1448, 0.1369]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1242, 0.1415, 0.1500, 0.1524, 0.1503, 0.1448, 0.1369]])\n",
      "atual tensor([[0.1243, 0.1415, 0.1499, 0.1523, 0.1502, 0.1448, 0.1370]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1243, 0.1415, 0.1499, 0.1523, 0.1502, 0.1448, 0.1370]])\n",
      "atual tensor([[0.1245, 0.1415, 0.1498, 0.1522, 0.1501, 0.1448, 0.1370]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1245, 0.1415, 0.1498, 0.1522, 0.1501, 0.1448, 0.1370]])\n",
      "atual tensor([[0.1247, 0.1415, 0.1498, 0.1521, 0.1501, 0.1448, 0.1371]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1247, 0.1415, 0.1498, 0.1521, 0.1501, 0.1448, 0.1371]])\n",
      "atual tensor([[0.1249, 0.1415, 0.1497, 0.1520, 0.1500, 0.1447, 0.1371]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1249, 0.1415, 0.1497, 0.1520, 0.1500, 0.1447, 0.1371]])\n",
      "atual tensor([[0.1250, 0.1416, 0.1496, 0.1519, 0.1499, 0.1447, 0.1372]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1250, 0.1416, 0.1496, 0.1519, 0.1499, 0.1447, 0.1372]])\n",
      "atual tensor([[0.1252, 0.1416, 0.1496, 0.1518, 0.1499, 0.1447, 0.1373]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1252, 0.1416, 0.1496, 0.1518, 0.1499, 0.1447, 0.1373]])\n",
      "atual tensor([[0.1254, 0.1416, 0.1495, 0.1517, 0.1498, 0.1447, 0.1373]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1254, 0.1416, 0.1495, 0.1517, 0.1498, 0.1447, 0.1373]])\n",
      "atual tensor([[0.1255, 0.1416, 0.1494, 0.1517, 0.1497, 0.1447, 0.1374]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1255, 0.1416, 0.1494, 0.1517, 0.1497, 0.1447, 0.1374]])\n",
      "atual tensor([[0.1257, 0.1416, 0.1494, 0.1516, 0.1497, 0.1447, 0.1374]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1257, 0.1416, 0.1494, 0.1516, 0.1497, 0.1447, 0.1374]])\n",
      "atual tensor([[0.1258, 0.1416, 0.1493, 0.1515, 0.1496, 0.1446, 0.1375]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1258, 0.1416, 0.1493, 0.1515, 0.1496, 0.1446, 0.1375]])\n",
      "atual tensor([[0.1260, 0.1416, 0.1492, 0.1514, 0.1495, 0.1446, 0.1375]])\n",
      "tensor(0.0002)\n",
      "anterior: tensor([[0.1260, 0.1416, 0.1492, 0.1514, 0.1495, 0.1446, 0.1375]])\n",
      "atual tensor([[0.1261, 0.1417, 0.1492, 0.1513, 0.1495, 0.1446, 0.1376]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1261, 0.1417, 0.1492, 0.1513, 0.1495, 0.1446, 0.1376]])\n",
      "atual tensor([[0.1263, 0.1417, 0.1491, 0.1513, 0.1494, 0.1446, 0.1376]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1263, 0.1417, 0.1491, 0.1513, 0.1494, 0.1446, 0.1376]])\n",
      "atual tensor([[0.1264, 0.1417, 0.1491, 0.1512, 0.1494, 0.1446, 0.1377]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1264, 0.1417, 0.1491, 0.1512, 0.1494, 0.1446, 0.1377]])\n",
      "atual tensor([[0.1266, 0.1417, 0.1490, 0.1511, 0.1493, 0.1446, 0.1377]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1266, 0.1417, 0.1490, 0.1511, 0.1493, 0.1446, 0.1377]])\n",
      "atual tensor([[0.1267, 0.1417, 0.1490, 0.1510, 0.1492, 0.1446, 0.1378]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1267, 0.1417, 0.1490, 0.1510, 0.1492, 0.1446, 0.1378]])\n",
      "atual tensor([[0.1268, 0.1417, 0.1489, 0.1510, 0.1492, 0.1446, 0.1378]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1268, 0.1417, 0.1489, 0.1510, 0.1492, 0.1446, 0.1378]])\n",
      "atual tensor([[0.1270, 0.1417, 0.1489, 0.1509, 0.1491, 0.1445, 0.1379]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1270, 0.1417, 0.1489, 0.1509, 0.1491, 0.1445, 0.1379]])\n",
      "atual tensor([[0.1271, 0.1417, 0.1488, 0.1508, 0.1491, 0.1445, 0.1379]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1271, 0.1417, 0.1488, 0.1508, 0.1491, 0.1445, 0.1379]])\n",
      "atual tensor([[0.1272, 0.1418, 0.1488, 0.1508, 0.1490, 0.1445, 0.1380]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1272, 0.1418, 0.1488, 0.1508, 0.1490, 0.1445, 0.1380]])\n",
      "atual tensor([[0.1274, 0.1418, 0.1487, 0.1507, 0.1490, 0.1445, 0.1380]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1274, 0.1418, 0.1487, 0.1507, 0.1490, 0.1445, 0.1380]])\n",
      "atual tensor([[0.1275, 0.1418, 0.1487, 0.1506, 0.1489, 0.1445, 0.1380]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1275, 0.1418, 0.1487, 0.1506, 0.1489, 0.1445, 0.1380]])\n",
      "atual tensor([[0.1276, 0.1418, 0.1486, 0.1506, 0.1489, 0.1445, 0.1381]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1276, 0.1418, 0.1486, 0.1506, 0.1489, 0.1445, 0.1381]])\n",
      "atual tensor([[0.1277, 0.1418, 0.1486, 0.1505, 0.1488, 0.1445, 0.1381]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1277, 0.1418, 0.1486, 0.1505, 0.1488, 0.1445, 0.1381]])\n",
      "atual tensor([[0.1279, 0.1418, 0.1485, 0.1504, 0.1488, 0.1445, 0.1382]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1279, 0.1418, 0.1485, 0.1504, 0.1488, 0.1445, 0.1382]])\n",
      "atual tensor([[0.1280, 0.1418, 0.1485, 0.1504, 0.1487, 0.1444, 0.1382]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1280, 0.1418, 0.1485, 0.1504, 0.1487, 0.1444, 0.1382]])\n",
      "atual tensor([[0.1281, 0.1418, 0.1484, 0.1503, 0.1487, 0.1444, 0.1382]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1281, 0.1418, 0.1484, 0.1503, 0.1487, 0.1444, 0.1382]])\n",
      "atual tensor([[0.1282, 0.1418, 0.1484, 0.1502, 0.1486, 0.1444, 0.1383]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1282, 0.1418, 0.1484, 0.1502, 0.1486, 0.1444, 0.1383]])\n",
      "atual tensor([[0.1283, 0.1418, 0.1483, 0.1502, 0.1486, 0.1444, 0.1383]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1283, 0.1418, 0.1483, 0.1502, 0.1486, 0.1444, 0.1383]])\n",
      "atual tensor([[0.1284, 0.1419, 0.1483, 0.1501, 0.1485, 0.1444, 0.1383]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1284, 0.1419, 0.1483, 0.1501, 0.1485, 0.1444, 0.1383]])\n",
      "atual tensor([[0.1285, 0.1419, 0.1483, 0.1501, 0.1485, 0.1444, 0.1384]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1285, 0.1419, 0.1483, 0.1501, 0.1485, 0.1444, 0.1384]])\n",
      "atual tensor([[0.1286, 0.1419, 0.1482, 0.1500, 0.1485, 0.1444, 0.1384]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1286, 0.1419, 0.1482, 0.1500, 0.1485, 0.1444, 0.1384]])\n",
      "atual tensor([[0.1288, 0.1419, 0.1482, 0.1500, 0.1484, 0.1444, 0.1385]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1288, 0.1419, 0.1482, 0.1500, 0.1484, 0.1444, 0.1385]])\n",
      "atual tensor([[0.1289, 0.1419, 0.1481, 0.1499, 0.1484, 0.1444, 0.1385]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1289, 0.1419, 0.1481, 0.1499, 0.1484, 0.1444, 0.1385]])\n",
      "atual tensor([[0.1290, 0.1419, 0.1481, 0.1498, 0.1483, 0.1443, 0.1385]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1290, 0.1419, 0.1481, 0.1498, 0.1483, 0.1443, 0.1385]])\n",
      "atual tensor([[0.1291, 0.1419, 0.1481, 0.1498, 0.1483, 0.1443, 0.1386]])\n",
      "tensor(0.0001)\n",
      "anterior: tensor([[0.1291, 0.1419, 0.1481, 0.1498, 0.1483, 0.1443, 0.1386]])\n",
      "atual tensor([[0.1292, 0.1419, 0.1480, 0.1497, 0.1482, 0.1443, 0.1386]])\n",
      "tensor(9.9674e-05)\n",
      "anterior: tensor([[0.1292, 0.1419, 0.1480, 0.1497, 0.1482, 0.1443, 0.1386]])\n",
      "atual tensor([[0.1293, 0.1419, 0.1480, 0.1497, 0.1482, 0.1443, 0.1386]])\n",
      "tensor(9.8258e-05)\n",
      "anterior: tensor([[0.1293, 0.1419, 0.1480, 0.1497, 0.1482, 0.1443, 0.1386]])\n",
      "atual tensor([[0.1294, 0.1419, 0.1479, 0.1496, 0.1482, 0.1443, 0.1387]])\n",
      "tensor(9.6858e-05)\n",
      "anterior: tensor([[0.1294, 0.1419, 0.1479, 0.1496, 0.1482, 0.1443, 0.1387]])\n",
      "atual tensor([[0.1295, 0.1419, 0.1479, 0.1496, 0.1481, 0.1443, 0.1387]])\n",
      "tensor(9.5472e-05)\n",
      "anterior: tensor([[0.1295, 0.1419, 0.1479, 0.1496, 0.1481, 0.1443, 0.1387]])\n",
      "atual tensor([[0.1295, 0.1419, 0.1479, 0.1495, 0.1481, 0.1443, 0.1387]])\n",
      "tensor(9.4131e-05)\n",
      "anterior: tensor([[0.1295, 0.1419, 0.1479, 0.1495, 0.1481, 0.1443, 0.1387]])\n",
      "atual tensor([[0.1296, 0.1420, 0.1478, 0.1495, 0.1481, 0.1443, 0.1387]])\n",
      "tensor(9.2834e-05)\n",
      "anterior: tensor([[0.1296, 0.1420, 0.1478, 0.1495, 0.1481, 0.1443, 0.1387]])\n",
      "atual tensor([[0.1297, 0.1420, 0.1478, 0.1494, 0.1480, 0.1443, 0.1388]])\n",
      "tensor(9.1538e-05)\n",
      "anterior: tensor([[0.1297, 0.1420, 0.1478, 0.1494, 0.1480, 0.1443, 0.1388]])\n",
      "atual tensor([[0.1298, 0.1420, 0.1478, 0.1494, 0.1480, 0.1443, 0.1388]])\n",
      "tensor(9.0286e-05)\n",
      "anterior: tensor([[0.1298, 0.1420, 0.1478, 0.1494, 0.1480, 0.1443, 0.1388]])\n",
      "atual tensor([[0.1299, 0.1420, 0.1477, 0.1494, 0.1479, 0.1442, 0.1388]])\n",
      "tensor(8.9064e-05)\n",
      "anterior: tensor([[0.1299, 0.1420, 0.1477, 0.1494, 0.1479, 0.1442, 0.1388]])\n",
      "atual tensor([[0.1300, 0.1420, 0.1477, 0.1493, 0.1479, 0.1442, 0.1389]])\n",
      "tensor(8.7857e-05)\n",
      "anterior: tensor([[0.1300, 0.1420, 0.1477, 0.1493, 0.1479, 0.1442, 0.1389]])\n",
      "atual tensor([[0.1301, 0.1420, 0.1477, 0.1493, 0.1479, 0.1442, 0.1389]])\n",
      "tensor(8.6650e-05)\n",
      "anterior: tensor([[0.1301, 0.1420, 0.1477, 0.1493, 0.1479, 0.1442, 0.1389]])\n",
      "atual tensor([[0.1302, 0.1420, 0.1476, 0.1492, 0.1478, 0.1442, 0.1389]])\n",
      "tensor(8.5518e-05)\n",
      "anterior: tensor([[0.1302, 0.1420, 0.1476, 0.1492, 0.1478, 0.1442, 0.1389]])\n",
      "atual tensor([[0.1303, 0.1420, 0.1476, 0.1492, 0.1478, 0.1442, 0.1390]])\n",
      "tensor(8.4370e-05)\n",
      "anterior: tensor([[0.1303, 0.1420, 0.1476, 0.1492, 0.1478, 0.1442, 0.1390]])\n",
      "atual tensor([[0.1303, 0.1420, 0.1476, 0.1491, 0.1478, 0.1442, 0.1390]])\n",
      "tensor(8.3268e-05)\n",
      "anterior: tensor([[0.1303, 0.1420, 0.1476, 0.1491, 0.1478, 0.1442, 0.1390]])\n",
      "atual tensor([[0.1304, 0.1420, 0.1475, 0.1491, 0.1477, 0.1442, 0.1390]])\n",
      "tensor(8.2150e-05)\n",
      "anterior: tensor([[0.1304, 0.1420, 0.1475, 0.1491, 0.1477, 0.1442, 0.1390]])\n",
      "atual tensor([[0.1305, 0.1420, 0.1475, 0.1490, 0.1477, 0.1442, 0.1390]])\n",
      "tensor(8.1092e-05)\n",
      "anterior: tensor([[0.1305, 0.1420, 0.1475, 0.1490, 0.1477, 0.1442, 0.1390]])\n",
      "atual tensor([[0.1306, 0.1420, 0.1475, 0.1490, 0.1477, 0.1442, 0.1391]])\n",
      "tensor(8.0049e-05)\n",
      "anterior: tensor([[0.1306, 0.1420, 0.1475, 0.1490, 0.1477, 0.1442, 0.1391]])\n",
      "atual tensor([[0.1307, 0.1420, 0.1474, 0.1490, 0.1476, 0.1442, 0.1391]])\n",
      "tensor(7.9006e-05)\n",
      "anterior: tensor([[0.1307, 0.1420, 0.1474, 0.1490, 0.1476, 0.1442, 0.1391]])\n",
      "atual tensor([[0.1307, 0.1420, 0.1474, 0.1489, 0.1476, 0.1442, 0.1391]])\n",
      "tensor(7.8022e-05)\n",
      "anterior: tensor([[0.1307, 0.1420, 0.1474, 0.1489, 0.1476, 0.1442, 0.1391]])\n",
      "atual tensor([[0.1308, 0.1421, 0.1474, 0.1489, 0.1476, 0.1442, 0.1391]])\n",
      "tensor(7.7009e-05)\n",
      "anterior: tensor([[0.1308, 0.1421, 0.1474, 0.1489, 0.1476, 0.1442, 0.1391]])\n",
      "atual tensor([[0.1309, 0.1421, 0.1474, 0.1488, 0.1475, 0.1441, 0.1392]])\n",
      "tensor(7.6041e-05)\n",
      "anterior: tensor([[0.1309, 0.1421, 0.1474, 0.1488, 0.1475, 0.1441, 0.1392]])\n",
      "atual tensor([[0.1310, 0.1421, 0.1473, 0.1488, 0.1475, 0.1441, 0.1392]])\n",
      "tensor(7.5102e-05)\n",
      "anterior: tensor([[0.1310, 0.1421, 0.1473, 0.1488, 0.1475, 0.1441, 0.1392]])\n",
      "atual tensor([[0.1310, 0.1421, 0.1473, 0.1488, 0.1475, 0.1441, 0.1392]])\n",
      "tensor(7.4148e-05)\n",
      "anterior: tensor([[0.1310, 0.1421, 0.1473, 0.1488, 0.1475, 0.1441, 0.1392]])\n",
      "atual tensor([[0.1311, 0.1421, 0.1473, 0.1487, 0.1475, 0.1441, 0.1392]])\n",
      "tensor(7.3239e-05)\n",
      "anterior: tensor([[0.1311, 0.1421, 0.1473, 0.1487, 0.1475, 0.1441, 0.1392]])\n",
      "atual tensor([[0.1312, 0.1421, 0.1472, 0.1487, 0.1474, 0.1441, 0.1393]])\n",
      "tensor(7.2345e-05)\n",
      "anterior: tensor([[0.1312, 0.1421, 0.1472, 0.1487, 0.1474, 0.1441, 0.1393]])\n",
      "atual tensor([[0.1313, 0.1421, 0.1472, 0.1487, 0.1474, 0.1441, 0.1393]])\n",
      "tensor(7.1451e-05)\n",
      "anterior: tensor([[0.1313, 0.1421, 0.1472, 0.1487, 0.1474, 0.1441, 0.1393]])\n",
      "atual tensor([[0.1313, 0.1421, 0.1472, 0.1486, 0.1474, 0.1441, 0.1393]])\n",
      "tensor(7.0572e-05)\n",
      "anterior: tensor([[0.1313, 0.1421, 0.1472, 0.1486, 0.1474, 0.1441, 0.1393]])\n",
      "atual tensor([[0.1314, 0.1421, 0.1472, 0.1486, 0.1473, 0.1441, 0.1393]])\n",
      "tensor(6.9723e-05)\n",
      "anterior: tensor([[0.1314, 0.1421, 0.1472, 0.1486, 0.1473, 0.1441, 0.1393]])\n",
      "atual tensor([[0.1315, 0.1421, 0.1471, 0.1485, 0.1473, 0.1441, 0.1393]])\n",
      "tensor(6.8903e-05)\n",
      "anterior: tensor([[0.1315, 0.1421, 0.1471, 0.1485, 0.1473, 0.1441, 0.1393]])\n",
      "atual tensor([[0.1315, 0.1421, 0.1471, 0.1485, 0.1473, 0.1441, 0.1394]])\n",
      "tensor(6.8069e-05)\n",
      "anterior: tensor([[0.1315, 0.1421, 0.1471, 0.1485, 0.1473, 0.1441, 0.1394]])\n",
      "atual tensor([[0.1316, 0.1421, 0.1471, 0.1485, 0.1473, 0.1441, 0.1394]])\n",
      "tensor(6.7264e-05)\n",
      "anterior: tensor([[0.1316, 0.1421, 0.1471, 0.1485, 0.1473, 0.1441, 0.1394]])\n",
      "atual tensor([[0.1317, 0.1421, 0.1471, 0.1484, 0.1472, 0.1441, 0.1394]])\n",
      "tensor(6.6474e-05)\n",
      "anterior: tensor([[0.1317, 0.1421, 0.1471, 0.1484, 0.1472, 0.1441, 0.1394]])\n",
      "atual tensor([[0.1317, 0.1421, 0.1470, 0.1484, 0.1472, 0.1441, 0.1394]])\n",
      "tensor(6.5669e-05)\n",
      "anterior: tensor([[0.1317, 0.1421, 0.1470, 0.1484, 0.1472, 0.1441, 0.1394]])\n",
      "atual tensor([[0.1318, 0.1421, 0.1470, 0.1484, 0.1472, 0.1441, 0.1395]])\n",
      "tensor(6.4939e-05)\n",
      "anterior: tensor([[0.1318, 0.1421, 0.1470, 0.1484, 0.1472, 0.1441, 0.1395]])\n",
      "atual tensor([[0.1319, 0.1421, 0.1470, 0.1483, 0.1472, 0.1440, 0.1395]])\n",
      "tensor(6.4149e-05)\n",
      "anterior: tensor([[0.1319, 0.1421, 0.1470, 0.1483, 0.1472, 0.1440, 0.1395]])\n",
      "atual tensor([[0.1319, 0.1421, 0.1470, 0.1483, 0.1471, 0.1440, 0.1395]])\n",
      "tensor(6.3449e-05)\n",
      "anterior: tensor([[0.1319, 0.1421, 0.1470, 0.1483, 0.1471, 0.1440, 0.1395]])\n",
      "atual tensor([[0.1320, 0.1421, 0.1469, 0.1483, 0.1471, 0.1440, 0.1395]])\n",
      "tensor(6.2689e-05)\n",
      "anterior: tensor([[0.1320, 0.1421, 0.1469, 0.1483, 0.1471, 0.1440, 0.1395]])\n",
      "atual tensor([[0.1321, 0.1421, 0.1469, 0.1482, 0.1471, 0.1440, 0.1395]])\n",
      "tensor(6.1989e-05)\n",
      "anterior: tensor([[0.1321, 0.1421, 0.1469, 0.1482, 0.1471, 0.1440, 0.1395]])\n",
      "atual tensor([[0.1321, 0.1422, 0.1469, 0.1482, 0.1471, 0.1440, 0.1396]])\n",
      "tensor(6.1274e-05)\n",
      "anterior: tensor([[0.1321, 0.1422, 0.1469, 0.1482, 0.1471, 0.1440, 0.1396]])\n",
      "atual tensor([[0.1322, 0.1422, 0.1469, 0.1482, 0.1470, 0.1440, 0.1396]])\n",
      "tensor(6.0603e-05)\n",
      "anterior: tensor([[0.1322, 0.1422, 0.1469, 0.1482, 0.1470, 0.1440, 0.1396]])\n",
      "atual tensor([[0.1322, 0.1422, 0.1468, 0.1482, 0.1470, 0.1440, 0.1396]])\n",
      "tensor(5.9918e-05)\n",
      "anterior: tensor([[0.1322, 0.1422, 0.1468, 0.1482, 0.1470, 0.1440, 0.1396]])\n",
      "atual tensor([[0.1323, 0.1422, 0.1468, 0.1481, 0.1470, 0.1440, 0.1396]])\n",
      "tensor(5.9232e-05)\n",
      "anterior: tensor([[0.1323, 0.1422, 0.1468, 0.1481, 0.1470, 0.1440, 0.1396]])\n",
      "atual tensor([[0.1323, 0.1422, 0.1468, 0.1481, 0.1470, 0.1440, 0.1396]])\n",
      "tensor(5.8606e-05)\n",
      "anterior: tensor([[0.1323, 0.1422, 0.1468, 0.1481, 0.1470, 0.1440, 0.1396]])\n",
      "atual tensor([[0.1324, 0.1422, 0.1468, 0.1481, 0.1469, 0.1440, 0.1397]])\n",
      "tensor(5.7951e-05)\n",
      "anterior: tensor([[0.1324, 0.1422, 0.1468, 0.1481, 0.1469, 0.1440, 0.1397]])\n",
      "atual tensor([[0.1325, 0.1422, 0.1467, 0.1480, 0.1469, 0.1440, 0.1397]])\n",
      "tensor(5.7295e-05)\n",
      "anterior: tensor([[0.1325, 0.1422, 0.1467, 0.1480, 0.1469, 0.1440, 0.1397]])\n",
      "atual tensor([[0.1325, 0.1422, 0.1467, 0.1480, 0.1469, 0.1440, 0.1397]])\n",
      "tensor(5.6684e-05)\n",
      "anterior: tensor([[0.1325, 0.1422, 0.1467, 0.1480, 0.1469, 0.1440, 0.1397]])\n",
      "atual tensor([[0.1326, 0.1422, 0.1467, 0.1480, 0.1469, 0.1440, 0.1397]])\n",
      "tensor(5.6073e-05)\n",
      "anterior: tensor([[0.1326, 0.1422, 0.1467, 0.1480, 0.1469, 0.1440, 0.1397]])\n",
      "atual tensor([[0.1326, 0.1422, 0.1467, 0.1479, 0.1469, 0.1440, 0.1397]])\n",
      "tensor(5.5462e-05)\n",
      "anterior: tensor([[0.1326, 0.1422, 0.1467, 0.1479, 0.1469, 0.1440, 0.1397]])\n",
      "atual tensor([[0.1327, 0.1422, 0.1467, 0.1479, 0.1468, 0.1440, 0.1397]])\n",
      "tensor(5.4866e-05)\n",
      "anterior: tensor([[0.1327, 0.1422, 0.1467, 0.1479, 0.1468, 0.1440, 0.1397]])\n",
      "atual tensor([[0.1327, 0.1422, 0.1466, 0.1479, 0.1468, 0.1440, 0.1398]])\n",
      "tensor(5.4285e-05)\n",
      "anterior: tensor([[0.1327, 0.1422, 0.1466, 0.1479, 0.1468, 0.1440, 0.1398]])\n",
      "atual tensor([[0.1328, 0.1422, 0.1466, 0.1479, 0.1468, 0.1440, 0.1398]])\n",
      "tensor(5.3719e-05)\n",
      "anterior: tensor([[0.1328, 0.1422, 0.1466, 0.1479, 0.1468, 0.1440, 0.1398]])\n",
      "atual tensor([[0.1328, 0.1422, 0.1466, 0.1478, 0.1468, 0.1439, 0.1398]])\n",
      "tensor(5.3152e-05)\n",
      "anterior: tensor([[0.1328, 0.1422, 0.1466, 0.1478, 0.1468, 0.1439, 0.1398]])\n",
      "atual tensor([[0.1329, 0.1422, 0.1466, 0.1478, 0.1467, 0.1439, 0.1398]])\n",
      "tensor(5.2556e-05)\n",
      "anterior: tensor([[0.1329, 0.1422, 0.1466, 0.1478, 0.1467, 0.1439, 0.1398]])\n",
      "atual tensor([[0.1330, 0.1422, 0.1466, 0.1478, 0.1467, 0.1439, 0.1398]])\n",
      "tensor(5.2050e-05)\n",
      "anterior: tensor([[0.1330, 0.1422, 0.1466, 0.1478, 0.1467, 0.1439, 0.1398]])\n",
      "atual tensor([[0.1330, 0.1422, 0.1465, 0.1478, 0.1467, 0.1439, 0.1398]])\n",
      "tensor(5.1484e-05)\n",
      "anterior: tensor([[0.1330, 0.1422, 0.1465, 0.1478, 0.1467, 0.1439, 0.1398]])\n",
      "atual tensor([[0.1331, 0.1422, 0.1465, 0.1477, 0.1467, 0.1439, 0.1399]])\n",
      "tensor(5.0962e-05)\n",
      "anterior: tensor([[0.1331, 0.1422, 0.1465, 0.1477, 0.1467, 0.1439, 0.1399]])\n",
      "atual tensor([[0.1331, 0.1422, 0.1465, 0.1477, 0.1467, 0.1439, 0.1399]])\n",
      "tensor(5.0440e-05)\n",
      "anterior: tensor([[0.1331, 0.1422, 0.1465, 0.1477, 0.1467, 0.1439, 0.1399]])\n",
      "atual tensor([[0.1332, 0.1422, 0.1465, 0.1477, 0.1466, 0.1439, 0.1399]])\n",
      "tensor(4.9934e-05)\n",
      "19.000000000000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def unimodal_poisson_probabilities(num_classes, target_class, tau, device):\n",
    "    # https://proceedings.mlr.press/v70/beckham17a/beckham17a.pdf\n",
    "    _lambda = target_class[:, None]+0.5  # to ensure mode falls only on this class\n",
    "    j = torch.arange(num_classes, dtype=torch.float, device=device)[None]\n",
    "    log_pmf = j*torch.log(_lambda) - _lambda - torch.lgamma(j+1)\n",
    "    return torch.softmax(log_pmf/tau, 1)\n",
    "\n",
    "\n",
    "#descobrir maior tau\n",
    "\n",
    "valores = np.arange(0.1, 20.1, 0.1)\n",
    "prob_anterior = None\n",
    "tolerancia = 5e-5\n",
    "for tau in valores:\n",
    "    num_classes = torch.tensor(7)\n",
    "    target_class = torch.tensor([3])\n",
    "    prob = unimodal_poisson_probabilities(num_classes, target_class, tau, 'cpu')\n",
    "    print(\"anterior:\",prob_anterior)\n",
    "    print(\"atual\", prob)\n",
    "    \n",
    "    if prob_anterior is None:\n",
    "        prob_anterior = prob\n",
    "    else: \n",
    "        diff = torch.abs(prob - prob_anterior).max()\n",
    "        print(diff)\n",
    "        if diff < tolerancia:\n",
    "            print(tau)\n",
    "            break\n",
    "        else:\n",
    "            prob_anterior = prob\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
